{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "attentiveness_detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkK9KaL3p-R9",
        "colab_type": "text"
      },
      "source": [
        "# Attentivity Predictor using OpenCV\n",
        "\n",
        "\n",
        "This code can detect your eyes and alert when the user is in-attentive.\n",
        "\n",
        "### Algorithm\n",
        "\n",
        "Each eye is represented by 6 (x, y)-coordinates, starting at the left-corner of the eye (as if you were looking at the person), and then working clockwise around the eye:.\n",
        "\n",
        "\n",
        "### Condition\n",
        "\n",
        "It checks 20 consecutive frames and if the Eye Aspect ratio is lesser than 0.25, Alert is generated. We further calculate the attendence percentage through the various attentivity insights we generate.\n",
        "\n",
        "#### Relationship\n",
        "\n",
        "Attentiveness detection in Smart Attendence System\n",
        "\n",
        "#### Contributors\n",
        "\n",
        "[ Team The Bug Stops Here ]\n",
        "\n",
        "Gourab Chakraborty\n",
        "\n",
        "Divyansh Tripathi\n",
        "\n",
        "Yasharth Dubey \n",
        "\n",
        "Shresth Bharadia\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IJzk8x7p-R-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.spatial import distance\n",
        "from imutils import face_utils\n",
        "import imutils\n",
        "import dlib\n",
        "import cv2\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNq2fO6mp-SD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eye_aspect_ratio(eye):\n",
        "\tA = distance.euclidean(eye[1], eye[5])\n",
        "\tB = distance.euclidean(eye[2], eye[4])\n",
        "\tC = distance.euclidean(eye[0], eye[3])\n",
        "\tear = (A + B) / (2.0 * C)\n",
        "\treturn ear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5531Whdhp-SG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thresh = 0.25\n",
        "frame_check = 20\n",
        "detect = dlib.get_frontal_face_detector()\n",
        "predict = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8521WmWqp-SK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
        "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSyLYE3Fp-SO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap=cv2.VideoCapture(0)\n",
        "flag=0\n",
        "inattentive_time=0 \n",
        "lecture_time=time.time() #starts count of lecture time\n",
        "count_inattentive = 0\n",
        "count_attentive = 0\n",
        "print(\"Lecture Running\")\n",
        "while True:\n",
        "\tret, frame=cap.read()\n",
        "\tframe = imutils.resize(frame, width=450)\n",
        "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\tsubjects = detect(gray, 0)\n",
        "\tfor subject in subjects:\n",
        "\t\tshape = predict(gray, subject)\n",
        "\t\tshape = face_utils.shape_to_np(shape)   #converting to NumPy Array\n",
        "\t\tleftEye = shape[lStart:lEnd]\n",
        "\t\trightEye = shape[rStart:rEnd]\n",
        "\t\tleftEAR = eye_aspect_ratio(leftEye)\n",
        "\t\trightEAR = eye_aspect_ratio(rightEye)\n",
        "\t\tear = (leftEAR + rightEAR) / 2.0\n",
        "\t\tleftEyeHull = cv2.convexHull(leftEye)\n",
        "\t\trightEyeHull = cv2.convexHull(rightEye)\n",
        "\t\tcv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
        "\t\tcv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
        "\t\tend=0\n",
        "\t\t\n",
        "\t\tif ear < thresh:\n",
        "\t\t\tflag += 1\n",
        "\t\t\tprint (flag)\n",
        "\t\t\t\n",
        "\t\t\tstart=time.time()\n",
        "\t\t\tif flag >= frame_check:\n",
        "\t\t\t\t# calculate time blocks for inattentive time and sum\n",
        "\t\t\t\t\n",
        "\t\t\t\tcv2.putText(frame, \"**************ALERT!**************\", (10, 30),\n",
        "\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\t\t\t\tcv2.putText(frame, \"**************ALERT!**************\", (10,325),\n",
        "\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\t\t\tcount_inattentive = count_inattentive + 1  \n",
        "\n",
        "\t\t\t\t\n",
        "\t\t\t\t\n",
        "\t\telse:\n",
        "\t\t\tflag = 0\n",
        "\t\t\tcount_attentive = count_attentive + 1\n",
        "\tcv2.imshow(\"Frame\", frame)\n",
        "\tkey = cv2.waitKey(1) & 0xFF\n",
        "\tif key == ord(\"q\"):\n",
        "\t\tbreak\n",
        "current_time = time.time()\n",
        "#print(\"Sum is\", count_attentive + count_inattentive)  \n",
        "lecture_time = current_time - lecture_time   #gives net lecture time, substract inattentive time to get attentive... calculate attentive percentage.\n",
        "#print(\"div is:\", lecture_time / (count_attentive+ count_inattentive) )\n",
        "new_div = lecture_time / (count_attentive+ count_inattentive) \n",
        "attentive_time = count_attentive * new_div\n",
        "inattentive_time = count_inattentive * new_div\n",
        "attendence_percentage= ( attentive_time / lecture_time ) * 100\n",
        "\n",
        "print(\"**************************Lecture Over*********************\\n\")\n",
        "print(\"Lecture Time is:\", lecture_time ,\"\\n\")\n",
        "print(\"Inattentive Time is:\", inattentive_time ,\"\\n\")\n",
        "print(\"Attentive Time is:\", attentive_time ,\"\\n\")\n",
        "print(\"Today's attendence is:\", attendence_percentage ,\" % \\n\")\n",
        "cv2.destroyAllWindows()\n",
        "cap.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M02k5COWp-SR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}